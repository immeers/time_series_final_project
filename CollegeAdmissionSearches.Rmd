---
title: "College Admission Searches"
author: "Imogen Meers, Sarah Deussing, & Sarah Cernugel"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
subtitle: "Will the Top-Ranked Schools Change?"
---

## Introduction
This analysis will forecast the number of Google Searches for admissions data of the top five nationally ranked U.S. universities, in addition to another college of interest. The current U.S. News rankings are as follows:

  1. Princeton University
  2. Massachusetts Institute of Technology
  3. Harvard University
  4. Stanford University
  5. Yale University
  18. University of Notre Dame

Data was obtained from Google Search statistics for each school; the search terms are "[school name] admission." Each dataset contains two columns: the date and interest for the term. These are weekly time series with five years of data.

The interest column is not a total number of searches. Instead, the values represent search interest relative to the maximum in the five year period. Values for interest are scaled to range from zero to one hundred. 

Time-series analysis will be performed to identify trends and seasonality in each dataset. Following, a forecast will predict future weekly search amounts. Doing so will determine if specific schools are projected to rise or fall in popularity. The analysis will answer the following questions:

  1. How can each dataset be represented in a time series format?
  2. Is a school projected to have more/less relative searches than the current year?
  3. If so, when during the application cycle will these changes take place?

It is likely that a school projected to see a spike in admissions search numbers in the next year, may have an increase in the number of applications, and thus the difficulty of admission. This would be useful information to determine changes in admission rate and exclusivity of schools in the future.

The audience for this project are high school juniors and seniors, and admission counselors going through the college application process. These students can use the forecasted search numbers and possible ranking changes to determine which schools they should apply to and which may be more or less competitive in the next year. This project can be expanded to include any set of schools in which a person wants to apply. Additionally, the time series is both replicable and extendable. Forecasts are based on values from previous weeks, i.e. any new time series can be downloaded and run through the same process. Additionally, the current forecast period of one year can be extended if a stakeholder wants to look forward several years. 

## Initial Data Analysis & Visualization

```{r, message=FALSE, warning =FALSE}
library(forecast)
library(readr)
library(ggplot2)
library(stringr)
library(zoo)
library(dplyr)

file_paths = Sys.glob(file.path("./data", "*"))
data_sets = list()
college_names = list()

for (i in (1:length(file_paths))){
  
  college.data <- read_delim(file_paths[i], delim = ",", skip = 1)
  
  college_names[i] = str_extract(string= file_paths[i], pattern = "[a-z]*_admissions")
  
  colnames(college.data) <- c("Week", "Searches")
  
  college.ts <- ts(college.data$Searches, start = c(2020, 7), end = c(2025, 7), freq = 52) #weekly with a yearly season
  
  g = autoplot(college.ts) +
  geom_line(color = "black") + labs(title = college_names[i])
  
  print(g)
  data_sets[[i]] <- college.ts
}
```

#### Evaluating Predictability
The first step in the time series process is to check if each dataset is a random walk. If so, this means that the best possible forecast for this dataset is a naive forecast and there is no need to apply any modelling. The following code does so for all schools' data.
```{r Check for random walk}
for (i in (1:length(file_paths))){
  
  college.ts = data_sets[[i]]

  diff.ts <- diff(college.ts)
  
  print(Acf(diff.ts, main = college_names[i]))
}
```

All ACF plots show significant correlation after differencing meaning these time series are not random walks.

To further prove this, we will also perform hypothesis testing.
```{r}
for (i in (1:length(file_paths))){
  
  college.ts = data_sets[[i]]

  college.ar.1 <- Arima(college.ts, order = c(1, 0, 0))
  
  print(college_names[i])
  print(summary(college.ar.1))
  
  ar1_intercept <- summary(college.ar.1)$coef["ar1"]
  ar1_se <- sqrt(diag(college.ar.1$var.coef))['ar1']
  
  print(paste("Is significant?" , -1.96 > (ar1_intercept-1)/ar1_se))
}

```

We can conclude that all our coefficients are significantly different from 0. 

Null Hypothesis: beta = 1 (i.e., random walk)
Alternative Hypothesis: beta not equal to 1 (i.e., not random walk)

To be specific, our t-stat = (coefficient - 1)/s.e = 
t-stat = +-/1.96 at 95% confidence interval

All t-stat are < -1.96 so are significant, there is significant evidence to reject null hypothesis. These time series are not random walks. Therefore, we can continue with the time series process.

## Time Series Process & Forecasting Models
For each school, we will perform the following process.

  1. Determine the best time time series for the data. Nine time series will be created for each school
  
    1. Seasonal Naive
    2. Simple Exponential Smoothing
    3. TSLM : Time Series Linear Model
    4. Moving Average
    5. Holt-Winters
    6. Exponential Smoothing (ETS)
    7. Auto Arima
    8. Neural Network (NNAR)
    9. Sine/Cosine Encoding
  
  2. Find the best model for each school (comparing MAPE)
  3. Using the entire dataset as training and the best model from the previous step, forecast statistics for the next year (52 weeks).

The forecasts for each school will help determine how each school may rise or fall in popularity. 

#### Train/Valid Split
Validation data will be the last 52 weeks (one year).

Pre-processing steps include changes values of 0 to 1. Doing so will allow for the calculation of MAPE values. This change will keep these values still relatively low within the range of the time series values. 
```{r, message = FALSE}
nValid <- 52

train_data <- list()
valid_data <- list()
n_valid <- list()

for (i in 1:length(file_paths)) {
  
  college.ts <- data_sets[[i]]
  
  # Zeros will affect training ability and MAPE calculations, so make these instances = 1.
  college.ts[college.ts == 0] <- 1
  
  nTrain <- length(college.ts) - nValid
  
  train.ts <- window(college.ts, start = c(2020, 7), end = c(2020, nTrain))
  valid.ts <- window(college.ts, start = c(2020, nTrain + 1), end = c(2020, nTrain + nValid))
  
  # create train/valid for each school
  school <- sub("_.*", "", college_names[i])
  
  train_data[[school]] <- train.ts
  valid_data[[school]] <- valid.ts
  n_valid[[school]] <- nValid
  
  p <- autoplot(train.ts) + 
    autolayer(valid.ts) +
    ggtitle(paste("Train Test Split: ", school))+
    ylab("Interest")
  
  print(p)
}
```

All models listed above will be created for each schools' data.

#### (1) Seasonal Naive
A seasonal naive forecast takes the most recent seasonal value as the forecasted value. This model serves as the baseline for future models. 
```{r}
snaive_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]
  
  # create predictions
  seasonal.naive <- snaive(train.ts, h = nValid, level = 0)
  seasonal.naive.forecast <- forecast(seasonal.naive, h = n_valid[[i]], level = 0)
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  snaive_models[[school]] <- seasonal.naive.forecast
  
  p = autoplot(seasonal.naive.forecast, series = "Seasonal Naive") +
    autolayer(valid_data[[i]], series = "Observed") +
    geom_line(color = "black") + labs(title = college_names[i])

  print(p)
}
```

#### (2) Simple Exponential Smoothing
Simple exponential smoothing models take the weighted average of all past values, attributing more weight to more recent values. They assume additive error, with no trend or seasonality.
```{r}
ses_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]
  
  # create predictions
  ses <- ets(train.ts, model = "ANN", alpha = 0.5)
  ses.forecast <- forecast(ses, h = n_valid[[i]], level = 0)
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  ses_models[[school]] <- ses.forecast
  
  p = autoplot(ses.forecast, series = "Simple Exponential Smoothing") +
    autolayer(valid_data[[i]], series = "Observed") +
    geom_line(color = "black") + labs(title = college_names[i])

  print(p)
}
```

#### (3) TSLM : Time Series Linear Model
Based on the time series data, the model fit will have linear trend and include yearly seasonality. In creating this seasonality, dummy variables are implicitly created within the model and serve as predictors.
```{r}
tslm_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]
  
  # create predictions
  tslm <- tslm(train.ts ~ trend + season)
  tslm.forecast <- forecast(tslm, h = n_valid[[i]], level = 0)
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  tslm_models[[school]] <- tslm.forecast
  
  p = autoplot(tslm.forecast, series = "Time Series Linear Model") +
    autolayer(valid_data[[i]], series = "Observed") +
    geom_line(color = "black") + labs(title = college_names[i])

  print(p)
}
```

#### (4) Moving Average
A moving average forecast will take the last value of the training series as the predictive value. Although these are strong visuals, a centered moving average cannot be used for forecasting, as it takes values into the future in its calculations.
```{r}
moving_avg_trailing_models = list()
moving_avg_centered_models = list()

for (i in (1:length(file_paths))){
  
  college.ts = data_sets[[i]]

  ma.trailing <- rollmean(college.ts, k = 12, align = "right") #zoo
  ma.centered <- ma(college.ts, order = 12) #forecast
  
  last.ma.trailing <- tail(ma.trailing, 1) 
  last.ma.centered <- tail(ma.centered, 1) 
  
  nTrain <- length(college.ts) - n_valid[[i]]
  ma.trailing.pred <- ts(rep(last.ma.trailing, n_valid[[i]]), start = c(2020, nTrain + 1), 
                       end = c(2020, nTrain + n_valid[[i]]), freq = 52)
  ma.centered.pred <- ts(rep(last.ma.centered, n_valid[[i]]), start = c(2020, nTrain + 1), 
                       end = c(2020, nTrain + n_valid[[i]]), freq = 52)
  
   # save to list
  school <- sub("_.*", "", college_names[i])
  moving_avg_trailing_models[[school]] <- ma.trailing.pred
  moving_avg_centered_models[[school]] <- ma.centered.pred
  
  g = autoplot(college.ts) +
  autolayer(ma.trailing, series="Trailing MA")+
  autolayer(ma.centered, series="Centered MA")+
  geom_line(color = "black") + labs(title = college_names[i])
  
  print(g)
  
}
```

#### (5) Holt-Winters
Holt-Winters Exponential Smoothing model allows for a series with trend and seasonality. However, the model is not able to handle a frequency higher than 24. The dataset for analysis has a frequency of 52 (weekly).
```{r, eval = FALSE}
holt_winters_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]

  hwin.mod <- ets(train.ts, model = "MAA")

  # create predictions
  hwin.pred <- forecast(hwin.mod, h = n_valid[[i]], level = 0)
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  holt_winters_models[[school]] <- hwin.pred

  g = autoplot(college.ts) +
  autolayer(hwin.pred$mean, series = "Holt-Winters")+
  geom_line(color = "black") + labs(title = college_names[i])
  
  print(g)
  
}
```

#### (6) ETS/STLF
For a frequency higher than 24, it is recommended to use Seasonal and Trend Decomposition with Loess (STLF), which implicity uses an ETS model. This model decomposes the training data into three components: trend, seasonality, and error. A model is then fit on the deaseasonalized time series (therefore allowing a frequency of greater than 24) using ETS. The resulting forecast is then seasonalized for the output.
```{r}
ets_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]

  stlf.model <- stlf(train.ts)

  # create predictions
  ets.pred <- forecast(stlf.model, h = n_valid[[i]])
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  ets_models[[school]] <- ets.pred

  g = autoplot(college.ts) +
  autolayer(ets.pred$mean, series = "ETS")+
  geom_line(color = "black") + labs(title = college_names[i])
  
  print(g)
  
}
```

#### (7) Auto Arima
An ARIMA model is a form of an Autoregressive model, meaning that predictors are the past values of the series. The model takes three parameters: p (# autoregressive terms to model), d (# difference terms included), and q (# moving average terms included). An Auto ARIMA model implicitly picks the optimal values for each time series data.
```{r}
auto_arima_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]
  
  # create predictions
  auto.arima <- auto.arima(train.ts)
  arima.auto.forecast <- forecast(auto.arima, h = n_valid[[i]], level = 0)
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  auto_arima_models[[school]] <- arima.auto.forecast
  
  p = autoplot(arima.auto.forecast, series = "Auto Arima") +
    autolayer(valid_data[[i]], series = "Observed") +
    geom_line(color = "black") + labs(title = college_names[i])

  print(p)
}
```

#### (8) Neural Network Model: NNAR
A Neural Network model takes the predictors as inputs and included hidden nodes that take the weighted sum of the inputs. The model has four parameters: repeats (# neural networks fit), p (# non-seasonal lags included), P (# seasonal lags includeed), and size (# nodes in hidden layer).
```{r}
nnar_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]
  
  # create predictions
  p <- 12 # Number of previous time steps used for forecast
  P <- 1 # Number of previous seasonal values to use 
  size <- 7 # Number of hidden nodes 
  
  school.nnetar <- nnetar(train.ts, repeats = 20, p = p, P = P, size = size)
  nnetar.forecast <- forecast(school.nnetar, h = n_valid[[i]])
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  nnar_models[[school]] <- nnetar.forecast
  
  p = autoplot(nnetar.forecast, series = "NNAR") +
    autolayer(valid_data[[i]], series = "Observed") +
    geom_line(color = "black") + labs(title = college_names[i])

  print(p)
}
```

#### (9) Sine/Cosine Encoding
The trend of the search interest data can also be captured with sine and cosine encoding. As opposed to a linear or exponential trend over time, this model captures trend that repeats in a "wave" that looks like a sine or cosine function, where there are local maximums and minimums within each season (year) of data.
```{r}
wave_models = list()

for (i in (1:length(file_paths))){
  
  train.ts = train_data[[i]]
  
  # create predictions
  wave <- tslm(train.ts ~ season + I(sin(2*pi*trend/52)) + I(cos(2*pi*trend/52)))
  wave.forecast <- forecast(wave, h = n_valid[[i]], level = 0)
  
  # save to list
  school <- sub("_.*", "", college_names[i])
  wave_models[[school]] <- wave.forecast
  
  p = autoplot(wave.forecast, series = "Model with Sine/Cosine Seasonality") +
    autolayer(valid_data[[i]], series = "Observed") +
    geom_line(color = "black") + labs(title = college_names[i])

  print(p)
}
```


All models have been created and stored for each school. Models will now be compared using MAPE values.

#### Compare Models for Each School
Mean Absolute Percentage Error (MAPE) calculates the percentage error for the models on the validation data. For each school, the model with the lowest MAPE is the model that fit the data best.
```{r}
model_names <- c("SNAIVE", "SES", "TSLM", "ARIMA", "MA TRAILING", "NNAR", "ETS", "WAVE")

for (i in (1:length(file_paths))){
  
  snaive <- snaive_models[[i]]
  ses <- ses_models[[i]]
  tslm <- tslm_models[[i]]
  arima <- auto_arima_models[[i]]
  ma_trailing <- moving_avg_trailing_models[[i]]
  nnar <- nnar_models[[i]]
  ets <- ets_models[[i]]
  wave <- wave_models[[i]]
  
  snaive_mape <- accuracy(snaive, valid_data[[i]])["Test set", "MAPE"]
  ses_mape <- accuracy(ses, valid_data[[i]])["Test set", "MAPE"]
  tslm_mape <- accuracy(tslm, valid_data[[i]])["Test set", "MAPE"]
  arima_mape <- accuracy(arima, valid_data[[i]])["Test set", "MAPE"]
  ma_trailing_mape <- accuracy(ma_trailing, valid_data[[i]])["MAPE"]
  nnar_mape <- accuracy(nnar, valid_data[[i]])["Test set", "MAPE"]
  ets_mape <- accuracy(ets, valid_data[[i]])["Test set", "MAPE"]
  wave_mape <- accuracy(wave, valid_data[[i]])["Test set", "MAPE"]
  
  mape_values <- c(snaive_mape, ses_mape, tslm_mape, arima_mape, ma_trailing_mape, nnar_mape, ets_mape, wave_mape)
  mape_df <- data.frame(Model = model_names, MAPE = mape_values)
  
  school <- sub("_.*", "", college_names[[i]])
  #print(school)
  #print(mape_df)
  
  min_index <- which.min(mape_values)
  best_model <- model_names[min_index]
  
  cat(paste(school, "best model:", best_model, "\n"))
}
```

## Forecasting: Future Values
The datasets are stored as:

  1: harvard, 2: mit, 3; nd, 4: princeton, 5: stanford, 6: yale

A forecast for the next year will be created for each school using their respective best model from above. Then, the forecasted values will be compared to the values from the current year (forecast - current). A positive value represents a forecasted increase for 2025/26.
  
Harvard: Sine/Cosine Encoding (Wave)
```{r, message = False}
harvard.full <- tslm(data_sets[[1]] ~ season + I(sin(2*pi*trend/52)) + I(cos(2*pi*trend/52)))
harvard.forecast <- forecast(harvard.full, h = 52)
autoplot(harvard.forecast) + ggtitle("Harvard Forecast") + ylab("Search Interest")

# Look at August 1 - January 1 (application period)
college.data <- read_delim(file_paths[1], delim = ",", skip = 1)
app.period <- college.data %>% 
  filter(Week >= as.Date('2024-08-01') & Week <= as.Date('2025-01-01'))

last_date <- tail(college.data$Week, 1)
forecast.dates <- seq(from = last_date + 1, by = "week", length.out = length(harvard.forecast$mean))
forecast.data <- data.frame(Date = forecast.dates, Forecast = harvard.forecast$mean)
forecast.app.period <- forecast.data %>% 
  filter(Date >= as.Date('2025-08-01') & Date <= as.Date('2026-01-01'))

change <- forecast.app.period$Forecast - app.period$`harvard admissions: (United States)`
differences <- data.frame(Date = app.period$Week, Change = change)
differences$Date <- as.Date(differences$Date)

ggplot(differences, aes(x = Date, y = Change)) + 
  geom_line() +
  ggtitle("Harvard's Next Application Cycle - 2025/26") +
  geom_vline(xintercept = as.Date(c('2024-11-01', '2025-01-01')), 
             linetype = "dashed", color = "red", size = 1) +
  labs(x = "Date", y = "Change in Search Interest") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b")
```

MIT: ARIMA
```{r, message = False}
mit.full <- auto.arima(data_sets[[2]])
mit.forecast <- forecast(mit.full, h = 52)
autoplot(mit.forecast) + ggtitle("MIT Forecast") + ylab("Search Interest")

# Look at August 1 - January 1 (application period)
college.data <- read_delim(file_paths[2], delim = ",", skip = 1)
app.period <- college.data %>% 
  filter(Week >= as.Date('2024-08-01') & Week <= as.Date('2025-01-01'))

last_date <- tail(college.data$Week, 1)
forecast.dates <- seq(from = last_date + 1, by = "week", length.out = length(mit.forecast$mean))
forecast.data <- data.frame(Date = forecast.dates, Forecast = mit.forecast$mean)
forecast.app.period <- forecast.data %>% 
  filter(Date >= as.Date('2025-08-01') & Date <= as.Date('2026-01-01'))

change <- forecast.app.period$Forecast - app.period$`mit admissions: (United States)`
differences <- data.frame(Date = app.period$Week, Change = change)
differences$Date <- as.Date(differences$Date)

ggplot(differences, aes(x = Date, y = Change)) + 
  geom_line() +
  ggtitle("MIT's Next Application Cycle - 2025/26") +
  geom_vline(xintercept = as.Date(c('2024-11-01', '2025-01-01')), 
             linetype = "dashed", color = "red", size = 1) +
  labs(x = "Date", y = "Change in Search Interest") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b")
```

Notre Dame: Sine/Cosine Encoding (Wave)
```{r, message = False}
nd.full <- tslm(data_sets[[3]] ~ season + I(sin(2*pi*trend/52)) + I(cos(2*pi*trend/52)))
nd.forecast <- forecast(nd.full, h = 52)
autoplot(nd.forecast) + ggtitle("Notre Dame Forecast") + ylab("Search Interest")

# Look at August 1 - January 1 (application period)
college.data <- read_delim(file_paths[3], delim = ",", skip = 1)
app.period <- college.data %>% 
  filter(Week >= as.Date('2024-08-01') & Week <= as.Date('2025-01-01'))

last_date <- tail(college.data$Week, 1)
forecast.dates <- seq(from = last_date + 1, by = "week", length.out = length(nd.forecast$mean))
forecast.data <- data.frame(Date = forecast.dates, Forecast = nd.forecast$mean)
forecast.app.period <- forecast.data %>% 
  filter(Date >= as.Date('2025-08-01') & Date <= as.Date('2026-01-01'))

change <- forecast.app.period$Forecast - app.period$`notre dame admissions: (United States)`
differences <- data.frame(Date = app.period$Week, Change = change)
differences$Date <- as.Date(differences$Date)

ggplot(differences, aes(x = Date, y = Change)) + 
  geom_line() +
  ggtitle("Notre Dame's Next Application Cycle - 2025/26") +
  geom_vline(xintercept = as.Date(c('2024-11-01', '2025-01-01')), 
             linetype = "dashed", color = "red", size = 1) +
  labs(x = "Date", y = "Change in Search Interest") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b")
```

Princeton: Sine/Cosine Encoding (Wave)
```{r, message = False}
princeton.full <- tslm(data_sets[[4]] ~ season + I(sin(2*pi*trend/52)) + I(cos(2*pi*trend/52)))
princeton.forecast <- forecast(princeton.full, h = 52)
autoplot(princeton.forecast) + ggtitle("Princeton Forecast") + ylab("Search Interest")

# Look at August 1 - January 1 (application period)
college.data <- read_delim(file_paths[4], delim = ",", skip = 1)
app.period <- college.data %>% 
  filter(Week >= as.Date('2024-08-01') & Week <= as.Date('2025-01-01'))

last_date <- tail(college.data$Week, 1)
forecast.dates <- seq(from = last_date + 1, by = "week", length.out = length(princeton.forecast$mean))
forecast.data <- data.frame(Date = forecast.dates, Forecast = princeton.forecast$mean)
forecast.app.period <- forecast.data %>% 
  filter(Date >= as.Date('2025-08-01') & Date <= as.Date('2026-01-01'))

change <- forecast.app.period$Forecast - app.period$`princeton admissions: (United States)`
differences <- data.frame(Date = app.period$Week, Change = change)
differences$Date <- as.Date(differences$Date)

ggplot(differences, aes(x = Date, y = Change)) + 
  geom_line() +
  ggtitle("Princeton's Next Application Cycle - 2025/26") +
  geom_vline(xintercept = as.Date(c('2024-11-01', '2025-01-01')), 
             linetype = "dashed", color = "red", size = 1) +
  labs(x = "Date", y = "Change in Search Interest") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b")
```

Stanford: ARIMA
```{r, message = False}
stanford.full <- auto.arima(data_sets[[5]])
stanford.forecast <- forecast(stanford.full, h = 52)
autoplot(stanford.forecast) + ggtitle("Stanford Forecast") + ylab("Search Interest")

# Look at August 1 - January 1 (application period)
college.data <- read_delim(file_paths[5], delim = ",", skip = 1)
app.period <- college.data %>% 
  filter(Week >= as.Date('2024-08-01') & Week <= as.Date('2025-01-01'))

last_date <- tail(college.data$Week, 1)
forecast.dates <- seq(from = last_date + 1, by = "week", length.out = length(stanford.forecast$mean))
forecast.data <- data.frame(Date = forecast.dates, Forecast = stanford.forecast$mean)
forecast.app.period <- forecast.data %>% 
  filter(Date >= as.Date('2025-08-01') & Date <= as.Date('2026-01-01'))

change <- forecast.app.period$Forecast - app.period$`stanford admissions: (United States)`
differences <- data.frame(Date = app.period$Week, Change = change)
differences$Date <- as.Date(differences$Date)

ggplot(differences, aes(x = Date, y = Change)) + 
  geom_line() +
  ggtitle("Stanford's Next Application Cycle - 2025/26") +
  geom_vline(xintercept = as.Date(c('2024-11-01', '2025-01-01')), 
             linetype = "dashed", color = "red", size = 1) +
  labs(x = "Date", y = "Change in Search Interest") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b")
```

Yale: ETS
```{r, message = False}
yale.full <- stlf(data_sets[[6]])
yale.forecast <- forecast(yale.full, h = 52)
autoplot(yale.forecast) + ggtitle("Yale Forecast") + ylab("Search Interest")

# Look at August 1 - January 1 (application period)
college.data <- read_delim(file_paths[6], delim = ",", skip = 1)
app.period <- college.data %>% 
  filter(Week >= as.Date('2024-08-01') & Week <= as.Date('2025-01-01'))

last_date <- tail(college.data$Week, 1)
forecast.dates <- seq(from = last_date + 1, by = "week", length.out = length(yale.forecast$mean))
forecast.data <- data.frame(Date = forecast.dates, Forecast = yale.forecast$mean)
forecast.app.period <- forecast.data %>% 
  filter(Date >= as.Date('2025-08-01') & Date <= as.Date('2026-01-01'))

change <- forecast.app.period$Forecast - app.period$`yale admissions: (United States)`
differences <- data.frame(Date = app.period$Week, Change = change)
differences$Date <- as.Date(differences$Date)

ggplot(differences, aes(x = Date, y = Change)) + 
  geom_line() +
  ggtitle("Yale's Next Application Cycle - 2025/26") +
  geom_vline(xintercept = as.Date(c('2024-11-01', '2025-01-01')), 
             linetype = "dashed", color = "red", size = 1) +
  labs(x = "Date", y = "Change in Search Interest") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b")
```

## Conclusion 
The time series forecasting above provided a predictive analysis of admissions search interest for 6 universities: Harvard University, MIT, University of Notre Dame, Princeton University, Stanford University, and Yale University. The resultant outcomes are to follow.

  1. Harvard
  2. MIT
  3. Notre Dame
  4. Princeton
  5. Stanford
  6. Yale

## References

“2025 Best National Universities.” US News Rankings, US News, www.usnews.com/best-colleges/rankings/national-universities. Accessed 10 Feb. 2025. 

Shmueli, Galit. Practical Time Series Forecasting with R: A Hands-on Guide. Axelrod Schnall Publishers, 2024. 

## Appendix